/**
 * Verteilte Systeme Mitschrift
 * author: d4ryus - https://github.com/d4ruys/
 * vim:tw=80:ai:ts=4:sw=4:spell:foldmethod=expr:nonumber:norelativenumber:foldexpr=NumberFold():
 */

0. Einführung

    Verteiltes System (SW-Orientiert):
    System voneinander unabhängige Prozesse
    (SW-Komponenten), die auf verschiedenen vernetzten Rechnern zusammenarbeiten
    und einem Benutzer wie ein einziges System erscheinen.

    Verteiltes System (HW-Orientiert):
    Menge voneinander unabhängiger Kooperierenden Rechner, die einem Benutzer
    wie ein einziges System erscheinen.

    Transparenz!

    Client-Server-Modell

    Entferntes Objekt (Remote Object):
        - läuft auf Server-Machine
        - wird vom Object auf Client-Maschine benutzt über eine Schnittstelle

    Entfernte Methode: Methode eines entfernten Objektes
    Entfernte Prozedur: Prozedur/Funktionen die auf einer Server Maschine aufgerufen wird.

1. Remote Method Invocation (RMI)
1.1. Einführung

    CIS-Modell

    Server-Aufgaben: erzeugt entfernte Objekte
                     macht ihre Existenz bekannt
                     macht den Zugang zu ihnen möglich
                     wartet auf Clients, die sie benutzen

    Client-Aufgaben: Verschafft sich Zugang zu entfernten Objekten, und benutzt
                     sie

1.2. RMI - Architektur

    Kommunikationsachitektur: Protokollstack
    Ablaufmodell: 1. Registrierung: bind(), ...
                  2. Lokalisierung: lookup(), ...
                  3. Aufruf

    RMI-Registry: ein auf einer Server-Maschine laufendes Programm zur
                  Verwaltung entfernter Objekte. Realisiert einen Namensdienst:
                  Name -> Objektreferenz (Abbildung).

    Name: rmi://<server-maschine>:port/<remote object name>
           |     ||                ||
      ,---´      \/                \/
      |      optional,          optional,
      | default: localhost     default 1099
      |
      `-> nur, wenn server-maschine oder port angegeben.

    Objektreferenz:  maschinenlesbarer Wort, der den Zugriff auf ein Objekt
                     möglich macht.
                     Inhalt (im Allgemeinen): Server_Adresse
                                              Portnummer
                                              Object-ID
              ,->--------------------->-.
              |                         |
    Serialisierung/Deserialisierung: Umwandlung eines Objektes in einen
                     |               Byte-Strom.
                     `->umgesetzt

1.3. RMI - Entwicklung

    4 Komponenten: - Schnittstellendefinition
                   - Schnittstellenimplementierung
                   - Server ( main() )
                   - Client ( main() )

    JDK stellt zur Verfügung:
        Interfaces: Remote, Serializable
        Classes: Remote Object, Unicast Remote Object
        Exceptions: Remote

2. Remote Procedure Calls (RPC)
2.1. Einführung

    RFC 5521,4506,1833
        RPCv2 XDR Postmapper
    CIS-Modell
    Remote Procedure Call: Aufruf einer Prozedur in einem anderen Adressraum als
                           dem des Aufrufers.
    Remote Procedure
    Remote Programms: Logisch zusammenhängende Remote Procedures

2.2. RPC - Program-Modell

    C: main() mit Prozeduren, die entfernt sein können
    Normale C-Philosophie von Prozedur-Aufrufen, und über das Netzwerk hinweg:
    "single thread of control across a network"
    Request-Reply-Mechanismus.
    Unterschied entfernter <-> lokaler Aufruf:
        - keine Zeiger-Übergabe
        - keine gemeinsame globale Variablen
        - Performance
        - nur ein Parameter bei Aufruf von entfernten Prozeduren
               `--> kann struct sein

    Identifizierung von Remote Prozeduren
        - Internet-Adresse des Server Rechners
          (pros, vers, proc)
            |     |     `--> Prozedurnummer
            |     `-->Versionsnummer von Prozedur
            `--> Programm Nummer

2.3. RPC - Ablaufmodell

    1. Registrierung von entfernten Prozeduren durch den Server
    2. Lokalisierung von entfernten Prozeduren durch den Client
    3. Aufruf

2.4. Kommunikationsmodell

    Stack gemäß Schichtenmodell
    Middleware: Stubs

2.5. externe Datenmanipulation mit Codierung

    Informationen + Parameter von Remote Prozedures müssen zur Übertragung
    codiert/decodiert werden (= ASM1 + BER)

    IDD - Datentype werden mit Hilfe von RPC-Routinen codiert/decodiert

2.6. RPC - Messages

    Call (Request) | spezifiziert in RPC-Language (C-ähnlich)
    Reply          | codiert mit Hilfe von XDR.

2.7. RPC - Entwicklungsprozess

    Zu entwickeln durch Anwender: Client, Server Prozeduren

    Im System generiert: Communication Stacks durch -> rpcgen <-
                         auf der Basis einer Schnittstellendefinition: *.x

3. Synchronisation im VS
3.1. Grundbegriffe

    Problem: - gemeinsame physikalische Zeit für Komponenten eines VS,
             - oder: allgemein im VS akzeptierte Ordnung von Aktionen und
               Ereignissen

    Lösung: Synchronisation

    Sync: Beeinflussung parallel arbeitender Prozesse dahingehen, dass ihre
          Aktionen/Ereignisse hinsichtlich ihres zeitlichen Ablaufs in eine von
          allen Prozessen akzeptierte Reihenfolge gebraucht werden.

    Zeitdienst: leitet die Sync von Prozessen in einem VS.
        `--> geleistet von einem Zeitserver.

3.2. Synchronisation physikalischer Rechneruhren
3.2.1. Systemmodell für physikalische Uhren

    Vorausgesetzt: C utc (t): Universelle Zeit, ausgegeben von einem zentralen
                              Zeitserver, z.B. NIST, PTB
                   C i (t)  : lokale Zeit eines Rechners i.
    Charakterisierung einer Rechneruhr: μ : universelle Abweichungsrate einer
                                           Rechneruhr
    Rechnerstellen gibt an:  mit: 1 - <= dc/dt <= 1t 

    Bedeutung: nach 1 Zeitintervall (z.B. 1 sec) weicht die Rechneruhr um maximal
               Zeiteinheiten von der physikalischen Uhr ab.
    Bedeutung: nach 1 Zeitintervall (z.B. 1 sec) weichen 2 Rechneruhren maximal
               2 μ Zeiteinheiten voneinander ab.

    Sollen zwei Uhren mit μ nie mehr als A Sekunden auseinander liegen dann
    müssen sie spätestens mit < Δt Sek. synchronisiert werden.

    Es gilt: A = 2 μ Δt
        => Δt = A/2 μ
            `--> nach dieser Zeit muss in einem VS auf 2 Komponenten
                 synchronisiert werden!
                 Δ μ

3.2.2. Algorithmen zum Sync physikalischen Rechneruhren

    Possium Zeitserver zentraler Algorithmus:

    Possium: C utc, I , To, T, ...
    Neu Setzten der Uhr des Zeitclients: neue zeit = C utc + (Ti - To - I)/2
                                                                 (Übertrag)
    Probleme: - Zentraler Server: Überlastung, Ausfall
              - Endl. Verarbeitungszeit ( >0 ) bei Zeitclient und Zeitserver
                Abhängigkeiten der Übertragunszeiten von Zeitanfrage und antwort
                von der Netzbelastung
              - n. Cl. Zeitübersetzung der Zeitclient-Uhr:
                => Zeitgesuchte nicht mehr eindeutig.

    Aktiver Zeitserver, zentraler Algorithmus

    - beruht auf Durchschnittsbildung von Zeiten.
    - Zeitserver sendet periodisch: Zeit requests
    - Zeitclient sendet daraufhin:  Zeit replies
    - Zeitserver sendet daraufhin:  Zeitkorrekturen (Δ abhängig)

    Wesentliches Problem: "Driften" der Zeit im gesamten VS.

3.2.3. Protokolle zur Sync. physikalischer Rechneruhren

    Network Time Protokoll NTP (RFC 1205)

    NTP: Anforderungen
         Architektur besteht aus Schichten (Strata).
         Operationsmodi
         Nachrichten

    Vereinfachung: SNTP (Simple NTP) (RFC 4320)
        Nachrichten: enthalten Zeitstempel:

            0                        31
            +-------------------------+
            | Sekunden, seit 1.1.1900 |
            |-------------------------|
            |   Sekundenbruchteile    |
            +-------------------------+

        Nachrichtenaustausch:

           |  ---- Zeitrequest  ----> |
           | <---- Zeitresponse ----  |

        mit den Zeitstempeln T1, T2, T3.

        Berechnet werden: - Offset: Gangunterschied der Zeitclientuhr zu
                                  Zeitserveruhr
                          - Round Trip Delay : Zur Ermittlung der Qualität der
                                               Zeitinfo vom Zeitserver

3.3. Ereignis-Anordnung durch logische Uhren
3.3.1. Lamport-Zeitstempel

    Def. Logische Uhr: immer weiter vorwärts laufender Zeitzähler
                                                         (1, 2, 3, 4, 5, 6, ...)

    Def. Logische Uhrzeit: Wert einer Logischen Uhr beim Auftretten eines
                           Ereignisses.
    Beschreibung: Relation "geschieht vor ", " --> "
                  a, b Ereignisse
                  Dann gilt "a geschieht vor b", alle Prozesse eines VS sind
                  sich einig, dass zuerst a stattfindet und danach b.

    Def. Relation"geschieht vor", " --> ":
        Für zwei Ereignisse a, b gilt a --> b in den folgenden beiden
        Situationen:
            - a und b sind Ereignisse im selben Prozess, und a tritt vor b auf.
            - a ist ein Sendeereignis bei einem Prozess, b ist das zugehörige
              Empfansereignis bei einem anderen Prozess
        Eigenschaften von " --> ":
            - Transitivität: a --> b, b --> c => a --> c
            - es ist möglich --> (a --> b) u. --> (b --> a): nebenläufige
              Ereignisse.

    Def. Zeitstempel eines Ereignisses a:
        Zeitstempel ((a): Wert einer logischen Uhr beim Einsetzten von a.

        Anforderung: a --> b <=> C(a) < C(b)

        Sog. Lampert-Zeitstempel erfüllen: a --> b => C(a) < C(b)

        Es gilt nicht: C(a) < C(b) => a --> b

    Um (*) im laufendem Verteilen System sicherzustellen:
        Lampert - Algorithmus

    "Wenn eine Nachricht gesendet wird, muss sie logisch später ankommen, also
    z.B. um eine Zeiteinheit später. Jede Nachricht enthält also ihren
    logischen Sendezeitpunkt mitgegeben, und der Empfänger stellt bei ihrem
    Empfang seine logische Zeit, wenn nötig, auf diese Zeit + 1 vor."

3.3.2. Vektor-Zeitstempel

    Def. Eine Vektor-Uhr Vi eines Prozesses Pi in einem VS mit N Prozessen P1,
         ..., PN ist ein Array von N logischen Uhren. Der momentare Wert einer
         Vektor-Uhr Vi wird als Vi[i:N]  bezeichnet mit den Komponenten Vi[j],
         j=1, ..., N.

    Beispiel: (2, 0, 1) ist momentaner Wert einer Vektor-Uhr in einem VS mit 3
              Komponenten.

    Def. Ein Vektor-Zeitstempel Ti[I:N] eines Prozesses Pi in einem VS mit N
         Prozessen is an einem Ereignis zugewiesen oder in einer Nachricht
         übertragener momentanen Wert seiner Vektor-Uhr Komponenten eines
         Vektor-Zeitstempels: Ti[j], j=1, ..., N

    bei e Ereignis: Zugehörige Vektorzeitstempel: V(e)

    Zum Anordnen von Ereignissen in einem VS mit Hilfe von Vektor-Zeitstempeln
    existieren sog. Aktualisierungsregeln.

    Austauschen von Vektorzeitstempeln:

        V =  V' <=> V[i] =  V'[i] ∀i
        V <= V' <=> V[i] <= V'[i]
        V <  V' <=> V    <= V'    nicht (V = V')

    Es gilt: a --> b <=> V(a) < V(b)

    Vektor-Zeitstempel können nebenläufig Ereignisse charakterisieren:
                                                `--> a, b

    ¬(V(a) <= V(b)) ¬(V(b) <= V(a))  a || b

    Beispiel: (5, 0, 1), (4, 1, 7)

4. CORBA
4.1. Einführung

    CIS-Systeme: - RMI
                 - RPC
                 - CORBA
                 - ESB

    CORBA-Spezifikation: OMG spezifizierte die OMA (Object Mgt. Arch.)

    OMA ---> Core Object Modell
         `-> Reference Modell ORB (Object Request Broker) und 

    Architektur des ORBs: CORBA: Common ORB Architecture

    CORBA ---> IDC Schnittstelle
           `-> Komponenten

4.2. Interface Description Language IDC

    Definition: IDC ist eine Spezifikation für Schnittstellen.

    IDC-Eigenschaften:

        - Unabhängigkeit von: Programmiersprachen,
                              Betriebssystemen,
                              HW-Architekturen

        - Reine Spez. Sprache: keine Statements
                               keine Variablen

    IDC-Grundkonstrukte: Types, ..., Operations, ..., Interfaces, ...

        Typen: Menge von Werten.

            - Objektreferenzen
            - Basistypen
            - benutzerdefinierte Typen - können z.T. zum Aufbau komplexer
                                         Typen verwendet werden

            Neue Typen definieren: typedef (typedef alter_typ neuer_typ)

        Beispiel: typedef long Kennziffer;

        Sequenzen: Arrays variabler Länge, maximale länge ist definierbar.

        Konstanten: Werte, die sich nicht ändern können.

        Exceptions: Typen, deren Werte dem Aufrufer einer Operation das
                    Auftreten von Fehlern mitteilen.

        Operations: Spezifikation von zu implementierenden Methoden bestehend aus:

                    - Rückgabetype, auch void möglich
                    - Name
                    - Argumentteile (in Liste von Argumenten mit jeweils Mode, Typ)
                    - Exceptions (optional)
                    Spezialfall angegebene Operationen: Operationen

        Attributes: Eigenschaften von Schnittstellen
                    Nicht unbedingt Notwendig.
                    Keine Variablen

        Interface: Typbeschreibungen
                   Vererbung zwischen Interfaces möglich
                     `--> sogar Mehrfachvererbung
                   Interfaces können nicht geschachtelt werden.

        Modules: dienen der Definition von Narmensbereichen, z.B. für mehrere
                 Interfaces
                 ! Jedem IDC-Konstante entsprechende Programmsprachen Konstrukte
                    zugeordnet, von daher: IDC Language Mapping.

4.3. Inter-ORB-Kommunikation
4.3.1. Interoperable Object References

    Notwendig für CIS-Kommunikation unter CORBA: IORs

    Bestandteile: Schnittstelleninformation
                  Profildaten (häufig über Server-Objekte: Adressen...Object
                     `-->vielfach möglich                              Key.)

4.3.2. GIOP und IIOP
       |        `--> Internet über ORB Protocol (Spezialisierung von GOP auf
       |                                         Internet Kommunikation))
       `--> gesendet über ORB-Protocol

    IIOP spezifiziert: Nachrichtenformate
                       Codierungsregeln: CDR Common Data Representation

    Ablauf der CORBA-Kommunikation mit Hilfe eines IOR:
        Ein Client besitzt die IOR eines Server-Objekts, das es ansprechen
        möchte. Dann baut er mit Hilfe von Internet-Adresse und
        Post-Nummer in der IOR eine TCP-Verbindung auf. Danach auf diese
        TCP-Verbindung Austausch von Request und Reply. Dabei enthalten die
        Requests: Object Key des Server Objekts, die Operation und ihre
                  Argumente.

4.4. CORBA Namensdienst

    Namensdienst realisiert eine Abbildung: Name -> Menge von Attributen
                                       z.B. Name -> {Objektreferenz}
                                            Name -> {Adresse}

    Begriffe:

        Namenskomponente: 2 Strings, der 2 wird nicht benutzt.

        Namensbindung:    Paar: Namenskomponente, Objektreferenz

        Namenskontext:    Menge von Namensbindungen

        Objektrefnummern können referenzieren: Anwendungsobjekte, weitere
                                               Namensobjekte
            => Namensgraphen

        Name: Folge von Namenskomponenten: Kontextname, .... Kontextname
                                           (elementarer Name)

        Namensdienst unterstützt:
            - resolve() von Client: finden einer Objektreferenz
            - send(), rebind() vom Server: Erschaffung eines Namensbindung

        Zusätzlich um eine Referenz auf den Namensdienst zu erlangen:
            resolve_initial_references()

5. Verteilte Datenbanken und verteilte Transaktionen
5.1. Grundbegriffe

    Def. Eine Verteilte DB ist eine DB deren Daten physisch auf mehrere
         Standorte (Rechner) verteilt sind, währen logisch gesehen dem Benutzer
         eine einzige DB präsentiert wird.

    An den einzelnen Standorten: lokale Datenbanken bzw. "Datenbankteile"

    Def. Eine verteilte Transaktion ist eine Transaktion, die auf den
         Datenbestand einer Verteilten DB arbeitet.

        Nachricht von verteilten DB: Komplexität!

    Def. Replication ist die mehrfache Speicherung von Daten an verschiedenen
         Standorten einer verteilten DB.
         Diese Daten heißen: Replikate, Duplikate, Kopie, Primary Copies, Slave
                             Copies

5.2. Entwurf von verteilten DBs

    mehrere Schritte:
        - normales: DB-Schema
        - Fragmentation: die Aufteilung von Daten einer DB in logische Einheiten
                         (Fragmente), beschreiben durch ein Fragmentationsschema
        - Allokation: Zuweisung von Fragmenten der physisch verschiedene
                      Standorte ein verteilten DB -> Allokationsschema
        - Replication: Erstellung und Verwaltung von Replikaten
                            -> Replikationsschema.

    zu Fragmentation bei relationalen Datenbanken:

        horizontale Fragmente: Zeilen, definiert durch (sigma)
            Beispiel: (sigma) (MITARBEITER)

        vertikale Fragmente: Spalten, definiert durch (pi)
            Beispiel: (pi vname nname) (MITARBEITER)

        gemischte Fragmente: definiert durch (pi), (sigma):
            Beispiel: (sigma)(pi) (MITARBEITER)

        +------------------------------------------------------+
        | Verteilung: Fragmentation + Allokation + Replikation |
        +------------------------------------------------------+

    Die Fragmentation ist eine Menge von Metadaten in Form von
        Guard Conditions + Attribute-Listen
          (sigma)                    (pi)
             |                        |
             +---> rel. Algebra >-----+

5.3. Anfragen in verteilte Datenbanken

    Problem: Minimierung von Datentransferkosten von Anfragen
    Problem: Dekomprition von Anfragen

5.4. Verteilte Transaktionen
5.4.1. Begriffe und Transaktionsmodell

    Motivation: Transaktionsabwicklung wiederum notwendig: ACID!

    Modell einer verteilten Transaktion:

        - lokale Transaktionen, die auf lokalen Datenbank-Teilen arbeiten:
          Participants, Worker kontrolliert durch einen lokalen
          Transaktionsmanager

        - ein Steuerprozess der das nebenläufige Arbeiten und eine eventuelle
          Recovery aller lokalen Transaktionen steuert:
            Koordinator

        Zusätzlich: 1 oder mehrere lock-Manager
        Grundprinzip:
            Eine verteilte Transaktion endet, wenn entweder:
                - alle ihre lokalen Transaktionen positiv terminieren
                - (comitten) oder negativ terminieren (aborten).

5.4.2. Concurrency Control durch 2PL-Verfahren
                                  `-> Two Phase Locking
    Praktisch verwendet: mehrere 2PL-Verfahren

    Alle involvieren: ein oder mehrere Lock Manager
                      ein Transaktions-Koordinator
                      lokale Transaktions-Manager, die jeweils lokal das
                          2PL-Protokoll umsetzten.

    Zentralisiertes 2PC:

        1 Transaktions-Koordinator
        1 zentraler Lock-Manager
        n lokale Transaktions-Manager

        2 Varianten: mit oder ohne Replikate von DB-Elementen.

    Primary Copy 2 PL

        1 Transaktions-Koordinator
        m Lock-Manager (m < n)
        n lokale Transaktions-Manager

    für jedes DB-Element:

        1 Primary Copy
        mehrere Slave Copies.

    Verteiltes 2PL:

        1 Transaktions-Koordinator
        n lokale Lock-Manager
        n lokale Transaktions-Manager

5.4.3. Recovery Control durch 2PC-Verfahren

    2PC stellt sicher: Global Commit Rule:
        - eine verteilte Transaktion kann nur dann commiten,
          wenn alle ihre lokalen Transaktionen committed haben
        - eine verteilte Transaktion muss aborten, wenn nur eine ihrer lokalen
          Transaktionen aborted.

    2PC hat 2 Phasen:
        Voting   Phase: Vorbereitung des Beendens einer verteilten Transaktion,
        Decision Phase: Beenden einer verteilten Transaktion

    Anlaufen des 2PC:
        - Koordinator hat den Participants genug Zeit gegeben,
        - Participants haben die Willen zur Beendigung signalisiert,
        - der Anwender der verteilten Transaktion hat "Ende" signalisiert.

    Beispiel für 2PC-Implementierung: CORBA-Transaktionsdienst.

    In der Praxis benutzt: primary copy 2PL + 2PC
                           für ACID mit einem verteilten System!

6. Grundalgorithmen in verteilten Systemen
6.1. Wahlalgorithmen

    Problem: Koordination ausgefallen,
             neuer Koordinator muss bestimmt/gewählt werden.

             => Algorithmus für Neuwahl nötig.

    Voraussetzung:
        - jeder Prozess im VS hat eine eindeutige Nr. oder ID,
          nach der die Prozesse geordnet werden können,
        - jeder Prozess kennt die Num. bzw. IDs aller anderen Prozesse des VS
        - kein Prozess im VS weiß über die Zustände der anderen Prozesse
          Bescheid ("arbeitet gerade", "wartet", "ausgefallen", ...)

    Algorithmen: Bully-Algorithmus
                 Ring-Algorithmus: Participants sind in einem logischem Ring
                                   organisiert.
